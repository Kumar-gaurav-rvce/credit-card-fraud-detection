{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d0fb2-2c1f-482b-bf4d-84bef749de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Load Fraud Detection Data from Amazon S3\n",
    "# ============================================\n",
    "\n",
    "# 1. Import required libraries\n",
    "import boto3   # AWS SDK for Python - allows interaction with S3\n",
    "import pandas as pd  # Data handling library\n",
    "\n",
    "# 2. Define S3 bucket and object (file) path\n",
    "bucket = \"ml-rvce-us-east-1\"                # Name of your S3 bucket\n",
    "key = \"fraud-detection/raw/creditcard.csv\"  # Path to the dataset inside the bucket\n",
    "\n",
    "# 3. Create an S3 client\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# 4. Download the dataset from S3 to local machine\n",
    "#    - First arg: bucket name\n",
    "#    - Second arg: object key (file path in S3)\n",
    "#    - Third arg: local filename to save as\n",
    "s3.download_file(bucket, key, \"creditcard.csv\")\n",
    "\n",
    "# 5. Load the downloaded CSV into a pandas DataFrame\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# 6. View the first 5 rows of the dataset\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1569f9a1-731d-4563-8722-9ca149084ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T14:57:50.291330Z",
     "iopub.status.busy": "2025-08-29T14:57:50.291016Z",
     "iopub.status.idle": "2025-08-29T14:57:50.313821Z",
     "shell.execute_reply": "2025-08-29T14:57:50.312795Z",
     "shell.execute_reply.started": "2025-08-29T14:57:50.291303Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Preprocessing: Feature Engineering\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Scale the \"Amount\" column\n",
    "# --------------------------------------------\n",
    "# - Transaction amounts vary a lot (some are tiny, some are huge).\n",
    "# - ML models often perform better when features are on a similar scale.\n",
    "# - StandardScaler transforms values to have:\n",
    "#     mean = 0, std = 1\n",
    "# - We use double square brackets df[['Amount']] to keep it as a DataFrame\n",
    "#   (since scaler expects 2D input).\n",
    "scaler = StandardScaler()\n",
    "df['Amount_Scaled'] = scaler.fit_transform(df[['Amount']])\n",
    "\n",
    "# 2. Create \"Hour of Day\" feature from Time column\n",
    "# --------------------------------------------\n",
    "# - 'Time' is given in seconds since the first transaction.\n",
    "# - To make it meaningful, we convert seconds → hours.\n",
    "# - (df['Time'] // 3600) gives hours since start.\n",
    "# - % 24 ensures values are in 0–23 (representing the hour of day).\n",
    "df['Hour'] = (df['Time'] // 3600) % 24\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632f1c53-ddb1-4389-8a65-e649f550ed30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T14:59:38.473983Z",
     "iopub.status.busy": "2025-08-29T14:59:38.473499Z",
     "iopub.status.idle": "2025-08-29T14:59:38.499635Z",
     "shell.execute_reply": "2025-08-29T14:59:38.498922Z",
     "shell.execute_reply.started": "2025-08-29T14:59:38.473955Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Feature Engineering: Behavior-Based Features\n",
    "# ============================================\n",
    "\n",
    "# 1. Compute the average transaction amount per hour\n",
    "# -------------------------------------------------\n",
    "# - Groups transactions by 'Hour'\n",
    "# - Calculates the mean 'Amount' within each hour group\n",
    "# - transform('mean') ensures the result aligns back to each row (same length as df)\n",
    "df['MeanAmountByHour'] = df.groupby('Hour')['Amount'].transform('mean')\n",
    "\n",
    "# 2. Create a ratio: transaction amount vs average amount for that hour\n",
    "# ---------------------------------------------------------------------\n",
    "# - Captures whether a transaction is unusually high/low compared to its hour's typical value\n",
    "# - Example: if avg at 3AM = $20, and transaction = $2000 → ratio = 100 (potential anomaly)\n",
    "# - Added 1e-6 (a very small number) to avoid division by zero\n",
    "df['Amount_vs_HourlyMean'] = df['Amount'] / (df['MeanAmountByHour'] + 1e-6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237de7bd-1897-4649-9960-8e5173e2a3fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T15:01:48.621162Z",
     "iopub.status.busy": "2025-08-29T15:01:48.620872Z",
     "iopub.status.idle": "2025-08-29T15:02:06.738700Z",
     "shell.execute_reply": "2025-08-29T15:02:06.737993Z",
     "shell.execute_reply.started": "2025-08-29T15:01:48.621138Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Train-Test Split and Save to S3\n",
    "# ============================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Separate features (X) and target (y)\n",
    "# ---------------------------------------\n",
    "# - 'Class' is the target variable (0 = normal, 1 = fraud)\n",
    "# - X contains all other engineered features\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# 2. Split into training and testing sets\n",
    "# ---------------------------------------\n",
    "# - test_size=0.2 → 20% for testing, 80% for training\n",
    "# - stratify=y → preserves fraud/non-fraud ratio in both sets\n",
    "# - random_state=42 → reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3. Recombine features + target for saving\n",
    "# -----------------------------------------\n",
    "# - concat along axis=1 → puts 'Class' back as first column\n",
    "train = pd.concat([y_train, X_train], axis=1)\n",
    "test = pd.concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a94923-5c8c-4f78-affe-5cfa9099eaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-29T15:27:38.788650Z",
     "iopub.status.busy": "2025-08-29T15:27:38.788213Z",
     "iopub.status.idle": "2025-08-29T15:27:43.175964Z",
     "shell.execute_reply": "2025-08-29T15:27:43.175266Z",
     "shell.execute_reply.started": "2025-08-29T15:27:38.788619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train model\n",
    "model = XGBClassifier(scale_pos_weight=10, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model locally\n",
    "joblib.dump(model, \"fraud_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb06e46-0ab6-474d-95fa-51b585d45f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
